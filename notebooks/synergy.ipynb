{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "The goal of this notebook is to compute synergy metrics between the stores/retailers/categories based on the cross visit data. We will use graph-based methods to analyze the relationships and interactions between different entities in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants.constants as cst\n",
    "import constants.paths as pth\n",
    "\n",
    "# Dim Tables\n",
    "dim_blocks = pd.read_csv(pth.DIM_BLOCKS, **cst.CSV_PARAMS)\n",
    "dim_malls = pd.read_csv(pth.DIM_MALLS, **cst.CSV_PARAMS)\n",
    "\n",
    "# Fact Tables\n",
    "fact_stores = pd.read_csv(pth.FACT_STORES, **cst.CSV_PARAMS)\n",
    "fact_malls = pd.read_csv(pth.FACT_MALLS, **cst.CSV_PARAMS)\n",
    "fact_sri_scores = pd.read_csv(pth.FACT_SRI_SCORES, **cst.CSV_PARAMS)\n",
    "\n",
    "# Store financials table\n",
    "store_financials = pd.read_csv(pth.STORE_FINANCIALS, **cst.CSV_PARAMS)\n",
    "\n",
    "# Cross visit table\n",
    "cross_visit = pd.read_csv(pth.CROSS_VISITS, **cst.CSV_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Data enriching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_blocks[dim_blocks[\"store_code\"].duplicated()].sort_values(\"store_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "We want to compute synergy metrics at the store level, retailer level and category level. For that, we need to enrich the cross visit data with retailer and category information. Additionally, to build graphs per mall, we add the mall id to the enriching data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_1_enrich = (\n",
    "    dim_blocks[\n",
    "        [\n",
    "            \"store_code\",\n",
    "            \"mall_id\",\n",
    "            \"retailer_code\",\n",
    "            \"bl1_label\",\n",
    "            \"bl2_label\",\n",
    "            \"bl3_label\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(\"store_code\")\n",
    "    .add_suffix(\"_1\")\n",
    ")\n",
    "\n",
    "store_2_enrich = (\n",
    "    dim_blocks[\n",
    "        [\n",
    "            \"store_code\",\n",
    "            \"mall_id\",\n",
    "            \"retailer_code\",\n",
    "            \"bl1_label\",\n",
    "            \"bl2_label\",\n",
    "            \"bl3_label\",\n",
    "        ]\n",
    "    ]\n",
    "    .drop_duplicates(\"store_code\")\n",
    "    .add_suffix(\"_2\")\n",
    ")\n",
    "\n",
    "cross_visit_enriched = pd.merge(\n",
    "    cross_visit,\n",
    "    store_1_enrich,\n",
    "    left_on=\"store_code_1\",\n",
    "    right_on=\"store_code_1\",\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    ")\n",
    "\n",
    "cross_visit_enriched = pd.merge(\n",
    "    cross_visit_enriched,\n",
    "    store_2_enrich,\n",
    "    left_on=\"store_code_2\",\n",
    "    right_on=\"store_code_2\",\n",
    "    how=\"left\",\n",
    "    validate=\"m:1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We check that there is no error in the `mall_id` (no mismatching `mall_id`). The only differences come from when one store has a mall_id and the other does not. Thus, we can combine the `mall_id` columns to get a full one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_visit_enriched[\n",
    "    (cross_visit_enriched[\"mall_id_1\"] != cross_visit_enriched[\"mall_id_2\"])\n",
    "    & (\n",
    "        cross_visit_enriched[\"mall_id_1\"].notna()\n",
    "        & cross_visit_enriched[\"mall_id_2\"].notna()\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_visit_enriched[\"mall_id\"] = cross_visit_enriched[\"mall_id_1\"].combine_first(\n",
    "    cross_visit_enriched[\"mall_id_2\"]\n",
    ")\n",
    "\n",
    "cross_visit_enriched = cross_visit_enriched.drop(columns=[\"mall_id_1\", \"mall_id_2\"])\n",
    "\n",
    "# Drop rows where mall_id is missing alltogether\n",
    "cross_visit_enriched = cross_visit_enriched.dropna(axis=0, subset=\"mall_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_visit_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We still need to normalize the edge weights to have comparable values. We can do:\n",
    "$$\n",
    "edge\\_weight_{ij} = \\frac{cross\\_total\\_cross\\_visits_{ij}}{\\sqrt{total\\_visits_i \\times {total\\_visits_j}}}\n",
    "$$\n",
    "\n",
    "At this point, the issue is that for some stores, there are more cross visits in `cross_visits` than total visits in `fact_stores`... Ask the question, but maybe use sum of cross visits as proxy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(data: pd.DataFrame, mall_id: int, granularity: str) -> nx.Graph:\n",
    "    \"\"\"Construct a graph for a specific mall and granularity level.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame containing cross visit data.\n",
    "    - mall_id: The mall ID to filter the data.\n",
    "    - granularity: The granularity level. Must be one of\n",
    "                   ('store', 'retailer', 'cat_high', 'cat_mid', 'cat_low').\n",
    "\n",
    "    Returns:\n",
    "    - A NetworkX graph object.\n",
    "    \"\"\"\n",
    "    if granularity == \"store\":\n",
    "        node_col_1 = \"store_code_1\"\n",
    "        node_col_2 = \"store_code_2\"\n",
    "    elif granularity == \"retailer\":\n",
    "        node_col_1 = \"retailer_code_1\"\n",
    "        node_col_2 = \"retailer_code_2\"\n",
    "    elif granularity == \"cat_high\":\n",
    "        node_col_1 = \"bl1_label_1\"\n",
    "        node_col_2 = \"bl1_label_2\"\n",
    "    elif granularity == \"cat_mid\":\n",
    "        node_col_1 = \"bl2_label_1\"\n",
    "        node_col_2 = \"bl2_label_2\"\n",
    "    elif granularity == \"cat_low\":\n",
    "        node_col_1 = \"bl3_label_1\"\n",
    "        node_col_2 = \"bl3_label_2\"\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Granularity must be one of 'store', 'retailer', 'cat_high', 'cat_mid' \"\n",
    "            \"or 'cat_low'.\"\n",
    "        )\n",
    "\n",
    "    mall_data = data[data[\"mall_id\"] == mall_id]\n",
    "\n",
    "    graph = nx.from_pandas_edgelist(\n",
    "        mall_data,\n",
    "        source=node_col_1,\n",
    "        target=node_col_2,\n",
    "        edge_attr=\"total_cross_visits\",\n",
    "        create_using=nx.Graph(),\n",
    "    )\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_graph = construct_graph(cross_visit_enriched, mall_id=22, granularity=\"store\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "17-urw-data-challenge (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
